# 电厂污染物排放预测系统模型训练与更新文档

## 1. 模型概述

电厂污染物排放预测系统采用多种深度学习模型来实现精准的排放预测和智能数据分析。主要包括以下几类模型：

1. **时序预测模型**：用于预测未来时段的污染物排放量
2. **自然语言处理模型**：用于理解和处理自然语言查询
3. **语音识别模型**：用于将语音转换为文本

本文档详细说明这些模型的架构、训练方法、参数调整和更新流程，供系统管理员和技术人员参考。

## 2. 时序预测模型

### 2.1 模型架构

系统实现了三种时序预测模型，针对不同规模的数据和预测要求，可以选择最合适的模型：

#### 2.1.1 LSTM模型

- **架构**：多层长短期记忆网络(LSTM)
- **层次结构**：
  - 输入层：接收特征向量
  - LSTM层1：128个单元，dropout=0.2
  - LSTM层2：64个单元，dropout=0.2
  - 全连接层：32个神经元，ReLU激活
  - 输出层：3个神经元(SO2、NOx、烟尘)，线性激活
- **优势**：能捕捉长期依赖关系，适合长序列预测
- **适用场景**：历史数据丰富，需要考虑长期影响因素

#### 2.1.2 GRU模型

- **架构**：多层门控循环单元网络(GRU)
- **层次结构**：
  - 输入层：接收特征向量
  - GRU层1：96个单元，dropout=0.2
  - GRU层2：48个单元，dropout=0.2
  - 全连接层：24个神经元，ReLU激活
  - 输出层：3个神经元(SO2、NOx、烟尘)，线性激活
- **优势**：计算效率高，参数更少，适合中等规模数据
- **适用场景**：计算资源有限，数据规模中等

#### 2.1.3 Transformer模型

- **架构**：基于自注意力机制的Transformer编码器
- **层次结构**：
  - 输入层：接收特征向量
  - 位置编码层：添加位置信息
  - Transformer编码器：4个头，2层，dropout=0.1
  - 全连接层：32个神经元，ReLU激活
  - 输出层：3个神经元(SO2、NOx、烟尘)，线性激活
- **优势**：能捕捉全局依赖关系，并行计算效率高
- **适用场景**：需要考虑全局时间依赖性，数据规模大

### 2.2 模型输入特征

#### 2.2.1 基本特征

时序预测模型使用以下基本特征：

1. **机组负荷**：机组发电负荷(MW)
2. **环境数据**：温度(°C)、湿度(%)、风速(m/s)、气压(hPa)
3. **历史排放**：前1小时、前3小时、前6小时、前12小时、前24小时的SO2、NOx、烟尘排放量
4. **运行参数**：锅炉效率(%)、供氧量、燃料品质指标
5. **时间特征**：小时、日、周、月、季节、是否假日

#### 2.2.2 特征工程

特征工程包括以下步骤：

1. **数据清洗**：去除异常值，填补缺失值
2. **特征标准化**：将特征缩放到均值为0、标准差为1
3. **滑动窗口**：创建大小为24的滑动窗口（表示24小时的历史数据）
4. **时间编码**：将时间信息编码为周期性特征（如一天中的小时、一周中的天等）
5. **特征交叉**：创建特征间的交互项（如负荷与温度的乘积）

### 2.3 模型训练

#### 2.3.1 数据准备

1. **数据集拆分**：
   - 训练集：70%
   - 验证集：15%
   - 测试集：15%
2. **时序划分**：保持时间上的连续性，避免数据泄露
3. **批次创建**：创建适合模型的批次数据（batch_size=32）

#### 2.3.2 训练参数

- **优化器**：Adam优化器
- **学习率**：初始0.001，使用学习率调度器
- **批大小**：32
- **训练轮数**：50轮（使用早停机制）
- **损失函数**：均方误差(MSE)
- **评估指标**：均方根误差(RMSE)、平均绝对误差(MAE)、决定系数(R²)

#### 2.3.3 训练流程

1. **准备数据**：加载数据，进行预处理和特征工程
2. **构建模型**：根据所选架构创建模型
3. **模型训练**：使用训练集进行迭代训练
   ```python
   # 训练代码示例（LSTM模型）
   model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])
   early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
   lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)
   
   history = model.fit(
       X_train, y_train,
       epochs=50,
       batch_size=32,
       validation_data=(X_val, y_val),
       callbacks=[early_stopping, lr_scheduler],
       verbose=1
   )
   ```
4. **模型评估**：使用验证集评估模型性能
5. **超参数调优**：使用网格搜索或贝叶斯优化调整超参数
6. **模型保存**：保存训练好的模型权重和配置

### 2.4 模型评估

使用以下指标评估模型性能：

1. **均方根误差(RMSE)**：预测值与实际值差异的标准差
2. **平均绝对误差(MAE)**：预测值与实际值差异的平均绝对值
3. **决定系数(R²)**：模型解释的方差比例，越接近1越好
4. **预测准确率**：预测值在允许误差范围内的比例
5. **超标预警准确率**：模型对超标事件的预警准确率

### 2.5 模型更新

#### 2.5.1 定期更新流程

1. **数据收集**：收集新的排放数据和相关特征
2. **数据整合**：将新数据与历史数据整合
3. **增量训练**：使用新数据和部分历史数据进行增量训练
   ```python
   # 增量训练示例
   model.fit(
       X_new, y_new,
       epochs=10,
       batch_size=32,
       validation_data=(X_val, y_val),
       verbose=1
   )
   ```
4. **性能评估**：评估更新后模型的性能
5. **模型部署**：将更新后的模型部署到生产环境

#### 2.5.2 触发更新条件

以下情况需要考虑更新模型：

1. **性能下降**：预测准确率低于阈值（如RMSE增加20%）
2. **环境变化**：季节变化、重大环境政策调整
3. **设备变更**：机组改造、环保设施升级
4. **定期更新**：每月或每季度定期更新
5. **数据积累**：新数据量达到原训练集的20%

## 3. 自然语言处理模型

### 3.1 模型架构

系统使用基于DeepSeek-8B的大语言模型处理自然语言查询，将其转换为SQL查询。

#### 3.1.1 基础模型

- **架构**：DeepSeek-8B（8B参数量的语言模型）
- **层次结构**：Transformer架构，包含多层自注意力层和前馈神经网络
- **输入处理**：使用分词器将文本转换为token序列
- **输出生成**：自回归方式生成SQL语句

#### 3.1.2 微调方法

采用Low-Rank Adaptation (LoRA) / QLoRA方法进行高效微调：

- **LoRA原理**：通过低秩分解矩阵更新部分参数
- **微调参数**：
  - LoRA秩(r)：16
  - LoRA alpha：32
  - 学习率：2e-4
  - 批处理大小：4
  - 训练轮数：3

### 3.2 训练数据

#### 3.2.1 数据来源

1. **通用NL2SQL数据集**：包含多种SQL查询模式
2. **电力行业专用数据**：电厂排放和运行数据查询场景
3. **人工生成数据**：针对特定查询需求手动创建的示例

#### 3.2.2 数据格式

```json
{
  "examples": [
    {
      "natural_language": "查询昨天所有机组的SO2平均排放量",
      "database_schema": "emissions(id, timestamp, unit_id, pollutant_type, concentration, standard_limit)",
      "sql": "SELECT AVG(concentration) FROM emissions WHERE pollutant_type='SO2' AND timestamp >= DATE_SUB(CURDATE(), INTERVAL 1 DAY) AND timestamp < CURDATE();"
    },
    // 更多示例...
  ]
}
```

### 3.3 训练流程

1. **数据准备**：准备训练数据，包含自然语言查询和对应的SQL
2. **提示模板**：构建提示模板，包含数据库模式信息和任务描述
   ```
   将以下自然语言查询转换为SQL:
   
   数据库模式:
   emissions(id, timestamp, unit_id, pollutant_type, concentration, standard_limit)
   units(id, name, capacity, location)
   
   自然语言查询: {query}
   
   SQL:
   ```
3. **模型微调**：使用LoRA方法进行微调
   ```python
   # 微调代码示例
   from peft import get_peft_model, LoraConfig
   
   peft_config = LoraConfig(
       r=16,
       lora_alpha=32,
       lora_dropout=0.1,
       task_type="CAUSAL_LM",
       target_modules=["q_proj", "v_proj"]
   )
   
   model = get_peft_model(base_model, peft_config)
   
   trainer = Trainer(
       model=model,
       train_dataset=train_dataset,
       eval_dataset=val_dataset,
       args=training_args
   )
   
   trainer.train()
   ```
4. **评估与测试**：评估模型的SQL生成准确率和执行正确率
5. **改进与优化**：基于测试结果优化提示模板和训练数据

### 3.4 更新流程

1. **持续学习**：收集用户查询和反馈，扩充训练数据
2. **错误分析**：分析模型生成错误的SQL查询，找出改进点
3. **定期微调**：每季度或半年进行一次模型微调
4. **提示工程优化**：不断优化提示模板，提高模型理解准确率
5. **版本管理**：记录模型版本变更历史，支持回滚

## 4. 语音识别模型

### 4.1 模型架构

系统使用基于Whisper模型的语音识别系统，针对电力行业专业术语进行了微调。

#### 4.1.1 基础模型

- **架构**：Whisper-medium（中型Whisper模型）
- **输入处理**：音频信号转换为梅尔频谱图
- **编码器**：处理音频特征
- **解码器**：生成文本序列

#### 4.1.2 微调方法

- **微调参数**：
  - 学习率：1e-5
  - 批处理大小：8
  - 训练轮数：3
  - 评估指标：WER（词错误率）和CER（字错误率）

### 4.2 训练数据

#### 4.2.1 数据来源

1. **通用中文语音数据集**：如AISHELL
2. **电力行业专业术语录音**：包含特定术语的录音样本
3. **模拟用户查询**：模拟用户在实际环境中的语音查询

#### 4.2.2 数据处理

1. **音频预处理**：降噪、标准化音量
2. **数据增强**：添加背景噪音、调整语速、变换音调
3. **分段处理**：将长音频切分为较短片段
4. **转写标注**：为每段音频提供准确的文字转写

### 4.3 训练流程

1. **数据准备**：准备训练数据，包含音频和对应的文字转写
2. **特征提取**：从音频中提取梅尔频谱图特征
3. **模型微调**：基于预训练的Whisper模型进行微调
   ```python
   # 微调代码示例
   from transformers import WhisperForConditionalGeneration, WhisperProcessor, Seq2SeqTrainer
   
   model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-medium")
   processor = WhisperProcessor.from_pretrained("openai/whisper-medium")
   
   trainer = Seq2SeqTrainer(
       model=model,
       args=training_args,
       train_dataset=train_dataset,
       eval_dataset=val_dataset,
       tokenizer=processor.tokenizer,
       data_collator=data_collator,
   )
   
   trainer.train()
   ```
4. **评估与测试**：评估模型的WER和CER
5. **错误分析**：分析常见错误词汇和句型

### 4.4 更新流程

1. **数据收集**：收集真实用户语音查询样本
2. **错误改进**：针对识别错误较多的术语增加训练样本
3. **定期微调**：每半年进行一次模型微调
4. **环境适应**：针对不同噪音环境进行模型优化
5. **后处理规则**：添加专业术语纠正规则，提高识别准确率

## 5. 模型部署与服务

### 5.1 模型文件组织

模型文件存储在系统的`/data/models`目录下，按以下结构组织：

```
/data/models/
  ├── time_series/
  │   ├── lstm/
  │   │   ├── lstm_v1.2/
  │   │   │   ├── model.pt
  │   │   │   ├── config.json
  │   │   │   └── metadata.json
  │   │   └── ...
  │   ├── gru/
  │   └── transformer/
  ├── nlp/
  │   ├── nl2sql_v1.1/
  │   │   ├── model.bin
  │   │   ├── adapter_config.json
  │   │   └── tokenizer/
  │   └── ...
  └── speech/
      ├── whisper_power_v1.0/
      │   ├── model.bin
      │   ├── config.json
      │   └── processor/
      └── ...
```

### 5.2 模型加载

系统启动时会加载默认模型，也支持动态加载不同版本的模型：

```python
# 模型加载示例
def load_model(model_type, model_version):
    model_path = os.path.join(DATA_DIR, "models", model_type, model_version)
    
    if model_type == "lstm":
        # 加载LSTM模型
        config_path = os.path.join(model_path, "config.json")
        with open(config_path, "r") as f:
            config = json.load(f)
        
        model = LSTMModel(**config["model_params"])
        model.load_state_dict(torch.load(os.path.join(model_path, "model.pt")))
        return model
    
    elif model_type == "nl2sql":
        # 加载NL2SQL模型
        return AutoModelForCausalLM.from_pretrained(
            model_path,
            device_map="auto",
            torch_dtype=torch.float16
        )
    
    # 其他模型类型...
```

### 5.3 模型推理优化

为了提高推理效率，系统采用以下优化策略：

1. **模型量化**：使用INT8量化减少内存占用
2. **批处理推理**：合并多个请求进行批处理推理
3. **模型缓存**：缓存常用模型避免重复加载
4. **异步推理**：使用异步处理避免阻塞

### 5.4 模型版本管理

系统使用以下方式管理模型版本：

1. **版本命名**：使用语义化版本号（如v1.2.3）
2. **元数据记录**：每个模型版本包含元数据文件，记录训练参数、性能指标等
3. **回滚机制**：支持快速回滚到之前的模型版本
4. **AB测试**：支持同时部署多个版本进行对比测试

## 6. 模型性能评估

### 6.1 评估指标

不同类型的模型使用不同的评估指标：

1. **时序预测模型**：
   - RMSE（均方根误差）
   - MAE（平均绝对误差）
   - R²（决定系数）
   - 超标预警准确率

2. **NL2SQL模型**：
   - SQL语法正确率
   - 查询执行成功率
   - 查询结果正确率
   - 平均响应时间

3. **语音识别模型**：
   - WER（词错误率）
   - CER（字错误率）
   - 识别速度（实时因子）
   - 专业术语识别准确率

### 6.2 定期评估流程

1. **准备测试集**：使用独立的测试数据集
2. **模型运行**：在测试环境中运行模型
3. **收集指标**：计算各项性能指标
4. **生成报告**：生成模型性能评估报告
5. **对比分析**：与历史版本性能对比

### 6.3 持续监控

在生产环境中持续监控模型性能：

1. **请求日志**：记录每次请求的输入和输出
2. **错误跟踪**：记录模型预测错误情况
3. **性能指标**：监控推理时间、资源使用等
4. **用户反馈**：收集用户对模型结果的反馈
5. **定期报告**：生成周报和月报分析模型性能变化

## 7. 常见问题与解决方案

### 7.1 模型训练问题

1. **问题**：训练过程中损失不收敛
   **解决方案**：
   - 检查学习率是否合适
   - 检查数据是否有异常值
   - 尝试不同的优化器
   - 检查模型架构是否过于复杂

2. **问题**：模型过拟合严重
   **解决方案**：
   - 增加正则化（如dropout）
   - 使用早停机制
   - 增加训练数据
   - 简化模型结构

3. **问题**：训练速度过慢
   **解决方案**：
   - 减小批大小
   - 使用混合精度训练
   - 优化数据加载流程
   - 使用更高效的硬件

### 7.2 模型部署问题

1. **问题**：模型加载失败
   **解决方案**：
   - 检查模型文件是否完整
   - 检查模型版本与环境兼容性
   - 检查硬件资源是否充足
   - 验证文件路径是否正确

2. **问题**：推理速度过慢
   **解决方案**：
   - 使用模型量化
   - 优化批处理大小
   - 使用更高效的推理引擎
   - 考虑模型蒸馏减小规模

3. **问题**：内存使用过高
   **解决方案**：
   - 使用低精度（如fp16/int8）
   - 优化模型加载方式
   - 实现模型部分加载
   - 增加服务器内存

### 7.3 预测准确率问题

1. **问题**：预测误差增大
   **解决方案**：
   - 检查数据分布是否变化
   - 使用最新数据重新训练
   - 调整特征工程流程
   - 考虑模型架构变更

2. **问题**：特定场景预测不准
   **解决方案**：
   - 针对该场景增加训练样本
   - 添加特定于该场景的特征
   - 考虑使用专门的模型处理该场景
   - 结合规则和模型的混合方法

## 8. 模型更新与维护计划

### 8.1 定期更新计划

| 更新类型 | 频率 | 内容 |
|---------|------|------|
| 例行更新 | 每月 | 使用新数据进行增量训练 |
| 模型评估 | 每季度 | 全面评估模型性能，生成报告 |
| 架构优化 | 每半年 | 考虑模型架构改进，引入新技术 |
| 全量更新 | 每年 | 使用积累的所有数据重新训练 |

### 8.2 应急更新流程

当出现以下情况时启动应急更新：

1. **性能显著下降**：关键指标下降超过20%
2. **环境突变**：环境或政策出现重大变化
3. **设备变更**：电厂设备有重大升级
4. **错误多发**：特定类型错误频繁出现

应急更新流程：

1. 分析问题原因
2. 收集相关数据
3. 快速训练更新模型
4. 测试性能改进
5. 快速部署更新

### 8.3 模型备份策略

1. **定期备份**：每次模型更新前进行备份
2. **存储策略**：
   - 本地存储：最近3个版本
   - 长期存储：所有正式发布版本
3. **元数据记录**：记录每个版本的训练参数、性能指标和使用时间
4. **恢复测试**：定期测试备份模型的恢复功能

## 9. 参考资料

1. LSTM模型架构：Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780.
2. GRU模型架构：Cho, K. et al. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation.
3. Transformer架构：Vaswani, A. et al. (2017). Attention is all you need.
4. LoRA微调方法：Hu, E. J. et al. (2021). LoRA: Low-Rank Adaptation of Large Language Models.
5. Whisper模型：Radford, A. et al. (2022). Robust Speech Recognition via Large-Scale Weak Supervision.
6. 时序预测最佳实践：https://github.com/azure/DeepLearningForTimeSeriesForecasting
7. DeepSeek官方文档：https://github.com/deepseek-ai/DeepSeek-LLM

---

**文档版本**：1.0.0
**最后更新**：2023-05-15
**文档作者**：技术团队 